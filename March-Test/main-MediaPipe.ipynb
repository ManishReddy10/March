{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af4d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #to read and process images\n",
    "import matplotlib.pyplot as plt #to show resultant images \n",
    "import mediapipe as mp\n",
    "\n",
    "# Initializing mediapipe pose class.\n",
    "mp_pose = mp.solutions.pose\n",
    "# Setting up the Pose model for images.\n",
    "pose_img = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5, model_complexity=1)\n",
    "# Setting up the Pose model for videos.\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, \n",
    "                          min_tracking_confidence=0.5, model_complexity=1)\n",
    "\n",
    "# Initializing mediapipe drawing class to draw landmarks on specified image.\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Calculate the angle between three points\n",
    "def calcul_angle2D(point1, point2, point3):\n",
    "    x1, y1, _ = point1\n",
    "    x2, y2, _ = point2\n",
    "    x3, y3, _ = point3\n",
    "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7160991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimPose_img(input_file, pose=pose_img, landmarks_c=(234,63,247), connection_c=(117,249,77), \n",
    "                   thickness=20, circle_r=10, display=True):\n",
    "    \n",
    "    # Read the input image\n",
    "    if isinstance(input_file, str) :\n",
    "        input_img = cv2.imread(input_file)\n",
    "    else :\n",
    "        input_img = input_file\n",
    "    \n",
    "    # Create a copy of the input image\n",
    "    output_img = input_img.copy()\n",
    "    \n",
    "    # Convert the image from BGR into RGB format.\n",
    "    RGB_img = cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Perform the Pose Detection.\n",
    "    results = pose.process(RGB_img)\n",
    "    \n",
    "    # Retrieve the height and width of the input image.\n",
    "    height, width, _ = input_img.shape\n",
    "    \n",
    "    # Initialize a list to store the detected landmarks.\n",
    "    landmarks = []\n",
    "    \n",
    "    # Check if any landmarks are detected.\n",
    "    if results.pose_landmarks:\n",
    "    \n",
    "        # Draw Pose landmarks on the output image.\n",
    "        mp_drawing.draw_landmarks(output_img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(landmarks_c, thickness, circle_r),\n",
    "                                  mp_drawing.DrawingSpec(connection_c, thickness, circle_r))\n",
    "        \n",
    "        # Iterate over the detected landmarks.\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            landmarks.append((int(landmark.x * width), int(landmark.y * height),\n",
    "                                  (landmark.z * width)))\n",
    "    \n",
    "    # Check if we want to display.\n",
    "    if display:\n",
    "        # Display the original input image and the resulting image.\n",
    "        plt.figure(figsize=[15,15])\n",
    "        plt.subplot(121);plt.imshow(input_img[:,:,::-1]);plt.title(\"Original image\");plt.axis('off');\n",
    "        plt.subplot(122);plt.imshow(output_img[:,:,::-1]);plt.title(\"Output image\");plt.axis('off');\n",
    "        \n",
    "        # Plot the Pose landmarks in 3D.\n",
    "        mp_drawing.plot_landmarks(results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "    # Just get output_img and landmarks\n",
    "    else:\n",
    "        # Return the output image and the found landmarks.\n",
    "        return output_img, landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d63bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimPose_img(r'Input\\bus.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def estimPose_video(input_file, pose_video=pose_video, landmarks_c=(234,63,247), connection_c=(117,249,77), \n",
    "                 thickness=5, circle_r=5, display=True, nrows_frames=4, ncols_frames=3):\n",
    "    \n",
    "    # Initialize the VideoCapture object to read from a video stored in the disk.\n",
    "    video = cv2.VideoCapture(input_file)\n",
    "    \n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames = []\n",
    "    \n",
    "    for i in range(total_frames):\n",
    "        # Read a frame.\n",
    "        ok, frame = video.read()\n",
    "    \n",
    "        # Check if frame is not read properly.\n",
    "        if not ok:\n",
    "            # Break the loop.\n",
    "            break\n",
    "        \n",
    "        # Get the width and height of the frame\n",
    "        frame_height, frame_width, _ =  frame.shape\n",
    "        # Resize the frame while keeping the aspect ratio.\n",
    "        frame = cv2.resize(frame, (int(frame_width * (640 / frame_height)), 640))\n",
    "        frame, _ = estimPose_img(frame, pose_video, landmarks_c, connection_c, thickness, \n",
    "                              circle_r, display=False)\n",
    "    \n",
    "        frames.append(frame)\n",
    "    \n",
    "    if display :\n",
    "        fig, axarr = plt.subplots(nrows_frames,ncols_frames,figsize=[15, 15])\n",
    "        k=0\n",
    "        for i in range(nrows_frames):\n",
    "            for j in range(ncols_frames):\n",
    "                axarr[i,j].imshow(frames[k][:,:,::-1]);axarr[i,j].axis('off')\n",
    "                k+=1\n",
    "    else:\n",
    "        return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df09fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimPose_video(r'Input\\Test Input Videos\\MarchingTo100BPM.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aa546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instanceaaaaaaaaaa\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Render detectiaaaons\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe609e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0591809",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            print(landmarks)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
